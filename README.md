# ZYNTH Labs â€“ Project Nyx

Nyx is a hybrid, autonomous personal assistant being developed under **ZYNTH Labs**. The longâ€‘term vision is to build a Jarvisâ€‘style background agent that silently manages calendar, memory, tasks, and multimodal inputs while only interrupting when necessary.

This repository currently contains the **Phase 1 foundation**:

* Modular agent loop
* Google Calendar integration
* Safetyâ€‘gated execution
* Swappable LLM backend
* Cost tracking scaffolding

---

##  Core Philosophy

* **Silent by default**: Nyx executes lowâ€‘risk tasks without notifying.
* **Plan before act**: Explicit analysis -> planning -> execution.
* **Human in the loop** for medium/highâ€‘risk actions.
* **Localâ€‘first mindset** with optional cloud fallback.
* **Strict modularity** so every component can be swapped later.

---

## ğŸ“ Project Structure

```
project_root/
â”‚
â”œâ”€â”€ main.py                # Scheduler + main Nyx loop
â”œâ”€â”€ config.py              # Secrets & pricing (gitignored)
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ collector.py       # Pulls calendar/context
â”‚   â”œâ”€â”€ reasoning.py       # Analysis + planning (LLM)
â”‚   â”œâ”€â”€ executor.py        # Executes safe actions
â”‚   â””â”€â”€ logger.py          # Central logging
â”‚
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ query.py           # LLM abstraction layer (OpenAI for now)
â”‚
â”œâ”€â”€ integrations/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ calendar_client.py # Google Calendar integration
â”‚
â”œâ”€â”€ credentials.json       # Google OAuth (local only, gitignored)
â”œâ”€â”€ token.json             # Google OAuth token (autoâ€‘generated, gitignored)
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Current Capabilities (Phase 1)

* Authenticated Google Calendar access (read/write)
* Periodic background scheduler (APScheduler)
* LLMâ€‘driven situation analysis
* LLMâ€‘driven action planning in strict JSON
* Safetyâ€‘gated execution (autoâ€‘run only lowâ€‘risk actions)
* Console logging of all actions
* Cost estimation scaffolding (INRâ€‘aware)

---

## ğŸš§ Current Status

âš ï¸ **Paused due to API credit requirement.**

The OpenAI API now requires **prepaid credits even for testing**. Until credits are added or a local LLM backend is wired in, Nyxâ€™s reasoning loop is paused.

All nonâ€‘LLM components (calendar, scheduler, executor) are already in place and ready.

---

## ğŸ” Security Rules

* `config.py`, `credentials.json`, and `token.json` are **never committed**.
* OpenAI key is restricted to **Responses API only**.
* Google OAuth app is in **testing mode with whitelisted users only**.
* All actions require explicit **risk classification** before execution.

---

## â–¶ï¸ How Nyx Runs (When Credits Are Available)

```bash
python main.py
```

* Nyx wakes up every `AGENT_INTERVAL_MINUTES`.
* Pulls calendar context.
* Runs **analysis â†’ planning â†’ execution**.
* Executes only lowâ€‘risk actions silently.
* Logs everything to the console.

---

## ğŸ§ª Development Mode

For offline testing without spending money:

* Replace `llm/query.py` with an **Ollamaâ€‘based local LLM client**.
* Keep the rest of the architecture unchanged.

---

## ğŸ§© Longâ€‘Term Vision

* Multimodal perception (image, video, audio)
* Longâ€‘term memory with embeddings
* Local inference via GPTâ€‘OSS / LLaMA / Qwen
* Voice wakeâ€‘word + speech I/O
* Hardware hub (edge device)

---

## ğŸ“ TODO (Live Roadmap)

### Phase 1 â€“ Stabilization

* [ ] Add terminalâ€‘based confirmation flow for mediumâ€‘risk actions
* [ ] Add persistent action logs in a database
* [ ] Add monthly cost aggregation + budget alerts
* [ ] Add robust JSON schema validation for planner outputs
* [ ] Graceful fallback when LLM API is unavailable

### Phase 2 â€“ Memory

* [ ] Design longâ€‘term memory schema (preferences, facts, habits)
* [ ] Add vector database for semantic memory
* [ ] Add explicit user confirmation for memory writes

### Phase 3 â€“ Multimodal

* [ ] Image parsing pipeline (OCR + vision model)
* [ ] Screenshot/UI understanding
* [ ] Whisperâ€‘based speechâ€‘toâ€‘text
* [ ] Audio output (TTS)

### Phase 4 â€“ Localâ€‘First Inference

* [ ] Swap OpenAI backend with Ollama
* [ ] Test GPTâ€‘OSS / Qwen / LLaMA models
* [ ] Add routing between local brain and cloud fallback

### Phase 5 â€“ Autonomy & UX

* [ ] Attention / interruption scoring
* [ ] Focusâ€‘mode awareness
* [ ] Daily silent summaries
* [ ] Minimal UI dashboard

---

## ğŸ·ï¸ Naming

* Organization: **ZYNTH Labs**
* Assistant: **Nyx**
* Current Version: `Nyx v0.x (Foundation Phase)`

Name changes only occur on **major version shifts**.

---

## ğŸ“Œ Resume Point

When credits are available, the next action is:

1. Reactivate OpenAI calls
2. Run first live autonomous calendar cycle
3. Enable confirmation flow for mediumâ€‘risk actions

---

*ZYNTH Labs - Building silent systems that think first and speak only when necessary.*
